{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1p4AJobXPmq5-d7iKGOUdcO0T2jaRCoga",
      "authorship_tag": "ABX9TyMNgPQcGtEotYZstGR0PpnN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Support Vector Machine**"
      ],
      "metadata": {
        "id": "NqHQczZgYyXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMoDJvNlEQX0",
        "outputId": "8ce3fd23-b0aa-438d-f18d-8341985b5e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    mpg  cylinders  displacement horsepower  weight  acceleration  year  \\\n",
            "0  18.0          8         307.0        130    3504          12.0    70   \n",
            "1  15.0          8         350.0        165    3693          11.5    70   \n",
            "2  18.0          8         318.0        150    3436          11.0    70   \n",
            "3  16.0          8         304.0        150    3433          12.0    70   \n",
            "4  17.0          8         302.0        140    3449          10.5    70   \n",
            "\n",
            "   origin                       name  \n",
            "0       1  chevrolet chevelle malibu  \n",
            "1       1          buick skylark 320  \n",
            "2       1         plymouth satellite  \n",
            "3       1              amc rebel sst  \n",
            "4       1                ford torino  \n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "auto = pd.read_csv('/content/drive/MyDrive/Auto.csv')\n",
        "print(auto.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part (a): Create the binary target variable\n",
        "# We create a binary variable that is 1 if mpg is above the median, and 0 otherwise.\n",
        "median_mpg = auto['mpg'].median()\n",
        "auto['high_mileage'] = (auto['mpg'] > median_mpg).astype(int)"
      ],
      "metadata": {
        "id": "5Sfpn4h1KVbZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop non-predictive columns for the analysis, such as 'mpg' and 'name'\n",
        "auto_data = auto.drop(columns=['mpg', 'name'])"
      ],
      "metadata": {
        "id": "WtXHBl1OK-ID"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part (b): Split the data into features and target variable\n",
        "X = auto_data.drop(columns=['high_mileage'])\n",
        "y = auto_data['high_mileage']\n",
        "\n",
        "# Handle non-numeric data in 'horsepower' column if needed by converting to numeric\n",
        "X['horsepower'] = pd.to_numeric(X['horsepower'], errors='coerce')\n",
        "\n",
        "# Replace any NaNs in 'horsepower' with the median value of the column\n",
        "X['horsepower'].fillna(X['horsepower'].median(), inplace=True)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define a range of C values for testing\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "results = {'C': [], 'F1_score': []}\n",
        "\n",
        "# Fit a linear SVC for each C value and record cross-validation F1-scores\n",
        "for C in C_values:\n",
        "    svc_linear = SVC(kernel='linear', C=C)\n",
        "    f1_scores = cross_val_score(svc_linear, X_scaled, y, cv=5, scoring='f1')\n",
        "    results['C'].append(C)\n",
        "    results['F1_score'].append(f1_scores.mean())\n",
        "\n",
        "# Display the linear kernel SVC results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"SVC Linear Kernel Cross-Validation Results\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWFH6ZsFLK1E",
        "outputId": "90ee768a-a0f8-468f-f352-20fa45207cea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-17168fa7f693>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['horsepower'].fillna(X['horsepower'].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC Linear Kernel Cross-Validation Results\n",
            "        C  F1_score\n",
            "0    0.01  0.881162\n",
            "1    0.10  0.827338\n",
            "2    1.00  0.809832\n",
            "3   10.00  0.833151\n",
            "4  100.00  0.838883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show that using a small value for C, especially C=0.01, gives the best balance for predicting whether a car gets high or low gas mileage. With C=0.01, we get the highest F1-score, meaning our model is both accurate and generalizes well without trying too hard to fit every little detail in the data. As we increase C (to values like 0.1, 1, 10, and 100), the model becomes stricter about classifying every point correctly, but the F1-score doesn’t improve much and even dips slightly. This tells us that the model doesn’t gain much from being overly complex, and keeping it simple with a low C actually works best for this task."
      ],
      "metadata": {
        "id": "J35pNlUpV2gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For part (c): Test radial (RBF) and polynomial kernel SVMs\n",
        "# Define parameter ranges for C, gamma, and degree\n",
        "gamma_values = [0.1, 1, 10]\n",
        "degree_values = [2, 3, 4]\n",
        "\n",
        "# Initialize dictionary to store results\n",
        "svm_results = {'Kernel': [], 'C': [], 'Gamma': [], 'Degree': [], 'F1_score': []}\n",
        "\n",
        "# Test Radial Basis Function (RBF) Kernel\n",
        "for C in C_values:\n",
        "    for gamma in gamma_values:\n",
        "        svc_rbf = SVC(kernel='rbf', C=C, gamma=gamma)\n",
        "        f1_scores = cross_val_score(svc_rbf, X_scaled, y, cv=5, scoring='f1')\n",
        "        svm_results['Kernel'].append('RBF')\n",
        "        svm_results['C'].append(C)\n",
        "        svm_results['Gamma'].append(gamma)\n",
        "        svm_results['Degree'].append(None)  # Degree is not used for RBF\n",
        "        svm_results['F1_score'].append(f1_scores.mean())\n",
        "\n",
        "# Test Polynomial Kernel\n",
        "for C in C_values:\n",
        "    for degree in degree_values:\n",
        "        svc_poly = SVC(kernel='poly', C=C, degree=degree)\n",
        "        f1_scores = cross_val_score(svc_poly, X_scaled, y, cv=5, scoring='f1')\n",
        "        svm_results['Kernel'].append('Polynomial')\n",
        "        svm_results['C'].append(C)\n",
        "        svm_results['Gamma'].append(None)  # Gamma is not used explicitly in poly in this context\n",
        "        svm_results['Degree'].append(degree)\n",
        "        svm_results['F1_score'].append(f1_scores.mean())\n",
        "\n",
        "# Convert results to DataFrame and display\n",
        "svm_results_df = pd.DataFrame(svm_results)\n",
        "print(\"SVM RBF and Polynomial Kernel Results\")\n",
        "print(svm_results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdyBwjotNm9Q",
        "outputId": "e89092fa-5373-41d1-a6fe-d60a08d35c6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM RBF and Polynomial Kernel Results\n",
            "        Kernel       C  Gamma  Degree  F1_score\n",
            "0          RBF    0.01    0.1     NaN  0.697655\n",
            "1          RBF    0.01    1.0     NaN  0.000000\n",
            "2          RBF    0.01   10.0     NaN  0.000000\n",
            "3          RBF    0.10    0.1     NaN  0.891554\n",
            "4          RBF    0.10    1.0     NaN  0.834600\n",
            "5          RBF    0.10   10.0     NaN  0.000000\n",
            "6          RBF    1.00    0.1     NaN  0.824650\n",
            "7          RBF    1.00    1.0     NaN  0.811188\n",
            "8          RBF    1.00   10.0     NaN  0.565067\n",
            "9          RBF   10.00    0.1     NaN  0.778045\n",
            "10         RBF   10.00    1.0     NaN  0.779145\n",
            "11         RBF   10.00   10.0     NaN  0.584012\n",
            "12         RBF  100.00    0.1     NaN  0.768339\n",
            "13         RBF  100.00    1.0     NaN  0.773366\n",
            "14         RBF  100.00   10.0     NaN  0.584012\n",
            "15  Polynomial    0.01    NaN     2.0  0.097586\n",
            "16  Polynomial    0.01    NaN     3.0  0.781380\n",
            "17  Polynomial    0.01    NaN     4.0  0.684184\n",
            "18  Polynomial    0.10    NaN     2.0  0.514436\n",
            "19  Polynomial    0.10    NaN     3.0  0.740477\n",
            "20  Polynomial    0.10    NaN     4.0  0.562618\n",
            "21  Polynomial    1.00    NaN     2.0  0.611562\n",
            "22  Polynomial    1.00    NaN     3.0  0.780944\n",
            "23  Polynomial    1.00    NaN     4.0  0.542726\n",
            "24  Polynomial   10.00    NaN     2.0  0.671360\n",
            "25  Polynomial   10.00    NaN     3.0  0.824283\n",
            "26  Polynomial   10.00    NaN     4.0  0.625397\n",
            "27  Polynomial  100.00    NaN     2.0  0.660672\n",
            "28  Polynomial  100.00    NaN     3.0  0.798043\n",
            "29  Polynomial  100.00    NaN     4.0  0.676357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the RBF kernel, the best performance happens when C=0.1 and gamma=0.1, giving a strong F1-score around 0.89, which means the model is well-balanced in capturing the patterns without overfitting. When\n",
        "gamma gets too high (like 10), the F1-score drops a lot, even to zero in some cases, showing that the model overfits and struggles with new data.\n",
        "\n",
        "For the polynomial kernel, degree 3 with C around 10 seems to work well, giving F1-scores around 0.82 to 0.83. Higher degrees or very low C values don’t perform as well, showing that too much complexity isn’t helpful for this dataset."
      ],
      "metadata": {
        "id": "lf23tlAcYRHL"
      }
    }
  ]
}